df$new = gsub("ó", "", df$new)
df$new = gsub("µ", "micro ", df$new)
df$new = gsub("µ", "micro ", df$new)
df$new
####################
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
tab = table(word.abs)
x =showNonASCII(names(tab))
df = data.frame(old=x, stringsAsFactors=FALSE)
df$new = df$old
df$new = gsub("áøs", "", df$new)
df$new = gsub("ò", "", df$new)
df$new = gsub("õs", "", df$new)
df$new = gsub("õ", "", df$new)
df$new = gsub("á", "", df$new)
df$new = gsub("ð", "-", df$new)
df$new = gsub("ó", "", df$new)
df$new = gsub("µ", "micro ", df$new)
df$new = gsub("ø", "", df$new)
df
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
tab = table(word.abs)
x =showNonASCII(names(tab))
df = data.frame(old=x, stringsAsFactors=FALSE)
df$new = df$old
df$new = gsub("áøs", "", df$new)
df$new = gsub("ò", "", df$new)
df$new = gsub("õs", "", df$new)
df$new = gsub("õ", "", df$new)
df$new = gsub("á", "", df$new)
df$new = gsub("ð", "-", df$new)
df$new = gsub("ó", "", df$new)
df$new = gsub("µ", "micro ", df$new)
df$new = gsub("ø", "", df$new)
df$new = gsub("ô", "", df$new)
df$new = gsub("ê", "", df$new)
df$new = gsub("ß", "fl", df$new)
showNonASCII(names(tab))
showNonASCII(df$new)
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
word.abs = gsub("áøs", "", word.abs)
word.abs = gsub("ò", "", word.abs)
word.abs = gsub("õs", "", word.abs)
word.abs = gsub("õ", "", word.abs)
word.abs = gsub("á", "", word.abs)
word.abs = gsub("ð", "-", word.abs)
word.abs = gsub("ó", "", word.abs)
word.abs = gsub("µ", "micro ", word.abs)
word.abs = gsub("ø", "", word.abs)
word.abs = gsub("ô", "", word.abs)
word.abs = gsub("ê", "", word.abs)
word.abs = gsub("ß", "fl", word.abs)
#### replacing stuff
tab = table(word.abs)
x =showNonASCII(names(tab))
# df = data.frame(old=x, stringsAsFactors=FALSE)
# df$new = df$old
dim(tab)
length(tab)
rm(list=ls())
library(tm)
library(stringr)
library(zoo)
library(plyr)
library(wordcloud)
library(reshape2)
library(tools)
library(ggplot2)
homedir = "~/Dropbox/database"
homedir = path.expand(homedir)
options(stringsAsFactors=FALSE)
mid = function (x, n = 6L, ...) {
stopifnot(length(n) == 1L)
nr = nrow(x)
mid = floor(nr/2)
n2 = floor(n/2)
start = max( mid - n2, 1)
end = min( mid + n2, nr)
ind = seq(start, end, by=1)
x[ind, , drop = FALSE]
}
abs.tab = function(x, min.n = 0){
tab = table(word=x)
tab = as.data.frame(tab, responseName = "nword")
tab = tab[ !(tab$word %in% ""),]
tab = tab[ order(tab$nword, decreasing=TRUE), ]
tab = tab[tab$nword > min.n,]
return(tab)
}
dftab = function(data, min.n = 0, change.u = FALSE){
tab = table(affil=data$affil)
tab = as.data.frame(tab, responseName = "nall")
tab = tab[ !(tab$affil %in% ""),]
tab = tab[ order(tab$nall, decreasing=TRUE), ]
tab = tab[tab$nall > min.n,]
if(change.u){
tab$affil = gsub("university", "u", tab$affil)
}
return(tab)
}
load(file=file.path(homedir,"Clean_Collapsed_2007_2013.Rda"))
nyears = length(unique(data$year))
ryear = range(data$year)
#### rename columns
data = rename(data, c("presenter1affiliation" = "affil"))
data = data[ !(data$affil %in% ""),]
data = data[ order(data$affil, data$year), ]
#
# data$affil[ grepl("new york at buffalo", data$affil) ] =
#   "SUNY at buffalo"
uaffil = unique(data$affil)
### subset over 1 per year
xtab = tab = dftab(data, min.n=nyears, change.u=FALSE)
tab$nall = NULL
coll = ddply(data, .(affil, year), summarise,
npeople = length(Talk_Title))
####### this is to subset the data
coll = merge(coll, tab, all.y=TRUE)
coll = coll[ order(coll$affil, coll$year), ]
coll = rename(coll, c("npeople" = "value"))
#### switch to wide to get all years, then switch back so that missing
### years are set to 0
coll = melt(coll,id=c("affil", "year"), na.rm=FALSE)
wide = dcast(coll, formula = affil  ~ year + variable)
wide[is.na(wide)] = 0
coll = melt(wide, id="affil")
coll$variable = as.numeric(gsub("_value","", coll$variable))
coll = rename(coll, c("variable"="year"))
coll = coll[ order(coll$affil, coll$year), ]
coll = merge(coll, location, all.x=TRUE)
coll$location = factor(coll$location)
## make a line plot - eh
g = ggplot(coll, aes(x = year, y = value, color=affil)) +
geom_line() +
guides(color=FALSE)
## bar -eh
gbar = ggplot(data=coll, aes(x=year, y=value, fill=affil)) +
geom_bar(stat="identity", position=position_dodge()) +
guides(fill=FALSE)
### had to have at least 1 per year
wtab = dftab(data, min.n=nyears, change.u=TRUE)
#### plotting different wordclouds for affiliations
pdfname = file.path(homedir,
paste0("Affiliations_Over",
nyears, "_wordcloud.pdf"))
pdf(pdfname, width=10, height=10)
wordcloud(words = wtab$affil,
freq = wtab$nall, random.order=FALSE)
title(main=paste0("Frequency of Affiliations for years",
ryear[1], " to ", ryear[2]))
dev.off()
cloud = function(wtab, year){
wordcloud(words = wtab$affil,
freq = wtab$nall, random.order=FALSE)
title(main=paste0("Frequency of Affiliations for Year: ",
year))
}
pdfname = file.path(homedir,
paste0("Affiliation_Each_Year_wordcloud.pdf"))
pdf(pdfname, width=10, height=10)
wtabs = dlply(data, .(year), dftab,
min.n=1, change.u=TRUE)
mapply(cloud, wtabs, names(wtabs))
wtabs = dlply(data, .(year), dftab,
min.n=1, change.u=FALSE)
mapply(cloud, wtabs, names(wtabs))
dev.off()
#######################
# Abstracts
####################
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
word.abs = gsub("áøs", "", word.abs)
word.abs = gsub("ò", "", word.abs)
word.abs = gsub("õs", "", word.abs)
word.abs = gsub("õ", "", word.abs)
word.abs = gsub("á", "", word.abs)
word.abs = gsub("ð", "-", word.abs)
word.abs = gsub("ó", "", word.abs)
word.abs = gsub("µ", "micro ", word.abs)
word.abs = gsub("ø", "", word.abs)
word.abs = gsub("ô", "", word.abs)
word.abs = gsub("ê", "", word.abs)
word.abs = gsub("ß", "fl", word.abs)
tab = abs.tab(word.abs, min.n=2)
dim(tab)
head(tab)
stopwords("english")
#######################
# Abstracts
####################
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
word.abs = gsub("áøs", "", word.abs)
word.abs = gsub("ò", "", word.abs)
word.abs = gsub("õs", "", word.abs)
word.abs = gsub("õ", "", word.abs)
word.abs = gsub("á", "", word.abs)
word.abs = gsub("ð", "-", word.abs)
word.abs = gsub("ó", "", word.abs)
word.abs = gsub("µ", "micro ", word.abs)
word.abs = gsub("ø", "", word.abs)
word.abs = gsub("ô", "", word.abs)
word.abs = gsub("ê", "", word.abs)
word.abs = gsub("ß", "fl", word.abs)
word.abs = removeWords(word.abs,
words=stopwords("english"))
#### replacing stuff
tab = abs.tab(word.abs, min.n=2)
head(tab)
install.packages("wordnet")
library(wordnet)
?getLemma
filter <- getTermFilter("StartsWithFilter", "car", TRUE)
initDict()
Sys.getenv("WMHOME")
?Sys.setenv()
rm(list=ls())
library(tm)
library(stringr)
library(zoo)
library(plyr)
library(wordcloud)
library(reshape2)
library(tools)
library(ggplot2)
library(wordnet)
wmhome= Sys.getenv("WMHOME")
if (wmhome == "") {
Sys.setenv(WMHOME="/opt/local/bin")
}
homedir = "~/Dropbox/database"
homedir = path.expand(homedir)
options(stringsAsFactors=FALSE)
rm(list=ls())
library(tm)
library(stringr)
library(zoo)
library(plyr)
library(wordcloud)
library(reshape2)
library(tools)
library(ggplot2)
wmhome= Sys.getenv("WMHOME")
if (wmhome == "") {
Sys.setenv(WMHOME="/opt/local/bin")
}
library(wordnet)
homedir = "~/Dropbox/database"
homedir = path.expand(homedir)
options(stringsAsFactors=FALSE)
initDict()
rm(list=ls())
library(tm)
library(stringr)
library(zoo)
library(plyr)
library(wordcloud)
library(reshape2)
library(tools)
library(ggplot2)
wmhome= Sys.getenv("WNHOME")
if (wmhome == "") {
Sys.setenv(WNHOME="/opt/local/bin")
}
library(wordnet)
initDict()
source('~/Dropbox/database/Plot_Data.R')
word.abs
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
word.abs
word.abs = gsub("áøs", "", word.abs)
word.abs = gsub("ò", "", word.abs)
word.abs = gsub("õs", "", word.abs)
word.abs = gsub("õ", "", word.abs)
word.abs = gsub("á", "", word.abs)
word.abs = gsub("ð", "-", word.abs)
word.abs = gsub("ó", "", word.abs)
word.abs = gsub("µ", "micro ", word.abs)
word.abs = gsub("ø", "", word.abs)
word.abs = gsub("ô", "", word.abs)
word.abs = gsub("ê", "", word.abs)
word.abs = gsub("ß", "fl", word.abs)
abs = removePunctuation(data$abstract)
abs = stripWhitespace(abs)
ss = strsplit(abs, " ")
word.abs = unlist(ss)
word.abs = gsub("áøs", "", word.abs)
word.abs = gsub("ò", "", word.abs)
word.abs = gsub("õs", "", word.abs)
word.abs = gsub("õ", "", word.abs)
word.abs = gsub("á", "", word.abs)
word.abs = gsub("ð", "-", word.abs)
word.abs = gsub("ó", "", word.abs)
word.abs = gsub("µ", "micro ", word.abs)
word.abs = gsub("ø", "", word.abs)
word.abs = gsub("ô", "", word.abs)
word.abs = gsub("ê", "", word.abs)
word.abs = gsub("ß", "fl", word.abs)
word.abs = removeWords(word.abs,
words=stopwords("english"))
word.abs = word.abs[ word.abs != ""]
#### replacing stuff
tab = abs.tab(word.abs, min.n=2)
x =showNonASCII(names(tab))
# df = data.frame(old=x, stringsAsFactors=FALSE)
# df$new = df$old
filter <- getTermFilter("StartsWithFilter", "car", TRUE)
terms <- getIndexTerms("NOUN", 5, filter)
sapply(terms, getLemma)
initDict()
library(tm)
?removeWords
removeWords
tm:::removeWords.character
library(devtools)
install_github("swirldev/swirl")
library(swirl)
swirl()
cars
cars$mpgCity
myMPG = cars$mpgCity
mean(myMPG)
median(myMPG)
back()
table(myMPG)
mode(myMPG)
19
swirl()
range(cars$price)
price
diff(range(cars$price))
var(cars$price)
sd(cars$price)
16
no
10
25
?swirl
swirl()
4
summary(cars$price)
10
25
4
summary(cars$price)
swirl()
swirl()
5+7
x <- 5+7
x
x - 3
y= x-3
y<-x-3
y
c(1.1, 9, 3.14)
z = c(1.1, 9, 3.14)
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z *2 + 100
sqrt(z-1)
mySqrt = sqrt(z-1)
mySqrt <- sqrt(z-1)
mySqrt
myDiv <- z / mySqrt
myDiv
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
swirl()
∫
"∫α + β"
"∫α + β"
?expr_creates_var
swirl:::expr_creates_var
swirl:::var_is_a
swirl:::var_is_a
swirl:::expr_creates_var
swirl:::expr_uses_func
swirl:::val_has_length
swirl:::expr_is_a
library(ggplot2)
library(reshape2)
library(plyr)
library(xtable)
library(data.table)
?ggplot2
?geom_hist
?geom_histogram
?data.table
?melt
names(airquality) <- tolower(names(airquality))
melt(airquality, id=c("month", "day"))
names(airquality) <- tolower(names(airquality))
melted = melt(airquality, id=c("month", "day"))
## plyr example
means = ddply(melted, .(variable), summarise,
mean.val = mean(value, na.rm=TRUE))
means
library(ggplot2)
?scale_color_brewer
?scale_color_continuous
df = data.frame(x = rnorm(100), y=rnorm(100), z= seq(-60, 40))
df = data.frame(x = rnorm(100), y=rnorm(100), z= seq(-60, 39))
g = ggplot(df, aes(x=x, y=y, colour=z)) + geom_point()
g
g+ scale_color_continuous(low="blue", high='red')
?scale_color_continuous
g+ scale_color_gradient(low="blue", high='red')
g+ scale_color_gradient2(low="blue", high='red')
?scale_color_gradient2(low="blue", high='red')
?scale_color_gradient2
?hotmetal
library(oro.dicom)
?hotmetal
library(oro.nift)
library(oro.nifti)
?hotmetal
scale_color_gradient2
continuous_scale
structure
?structure
x = c("the dog", "basdf asdf", ' asdf asd asd ')
x = strsplit(x, " ")
x
sapply(x, "[", 1)
str(x)
str(x,1)
?str
library(googleCite)
x = searchCite("Jonathan Taylor")
x = searchCite("B efron")
head(x)
x$"Journal name"
cn = colnames(x)
cn = gsub(" ", "_", cn)
colnames(x) = cn
headD(x)
head(x)
slide <- function(fname) {
require(slidify)
require(knitr)
slidify(fname)
fname <- gsub(".Rmd", ".html", fname)
system(sprintf('open %s', fname))
}
rm(list=ls())
library(rgl)
library(brainR)
library(misc3d)
library(oro.dicom)
library(oro.nifti)
library(AnalyzeFMRI)
library(knitcitations)
library(slidify)
library(dti)
library(plotrix)
rootdir <- "~/Dropbox/3DPDF_Example"
rootdir = path.expand(rootdir)
outdir <- file.path(rootdir, "Presentation")
homedir <- file.path(rootdir, "Paper")
datadir <- file.path(homedir, "data")
progdir <- file.path(homedir, "programs")
resdir <- file.path(homedir, "results")
install.packages("dti")
install.packages("dti")
rm(list=ls())
library(rgl)
library(brainR)
library(misc3d)
library(oro.dicom)
library(oro.nifti)
library(AnalyzeFMRI)
library(knitcitations)
library(slidify)
library(dti)
library(plotrix)
rootdir <- "~/Dropbox/3DPDF_Example"
rootdir = path.expand(rootdir)
outdir <- file.path(rootdir, "Presentation")
homedir <- file.path(rootdir, "Paper")
datadir <- file.path(homedir, "data")
progdir <- file.path(homedir, "programs")
resdir <- file.path(homedir, "results")
setwd(outdir)
slide <- function(fname) {
require(slidify)
require(knitr)
slidify(fname)
fname <- gsub(".Rmd", ".html", fname)
system(sprintf('open %s', fname))
}
slide("ENAR_Visualization_2014.Rmd")
slide("ENAR_Visualization_2014.Rmd")
slide("ENAR_Visualization_2014.Rmd")
